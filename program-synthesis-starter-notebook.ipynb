{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaL4","dataSources":[{"sourceId":67357,"databundleVersionId":8951125,"sourceType":"competition"},{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"},{"sourceId":13320711,"sourceType":"datasetVersion","datasetId":7010692}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n!echo $HOME\n!pwd\n!uname -a\n!cat /etc/debian_version\n!python --version\n\n!python -m cupyx.tools.install_library --library cudnn --cuda 12.x\n!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1\n!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1/lib/libcudnn_cnn_infer.so.8.8.1\n!cp -R /root/.cupy /kaggle/working\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !nvidia-smi\n# !nvcc --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T10:48:48.643872Z","iopub.execute_input":"2025-10-09T10:48:48.644135Z","iopub.status.idle":"2025-10-09T10:48:48.960375Z","shell.execute_reply.started":"2025-10-09T10:48:48.644114Z","shell.execute_reply":"2025-10-09T10:48:48.959419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !python -m cupyx.tools.install_library --library cudnn --cuda 12.x\n# !cp -R /root/.cupy /kaggle/working\n\n!cp -R /kaggle/working/.cupy /root\n!cp -R /kaggle/input/arc-prize-2025 /kaggle/working\n!cp -R /kaggle/input/tokpidjin      /kaggle/working\n\n%cd tokpidjin\n\n# !bash run_card.sh -o -i -b -c -32\n!python kaggle_test_gpu_o_g.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T17:39:12.469148Z","iopub.execute_input":"2025-10-11T17:39:12.469822Z","iopub.status.idle":"2025-10-11T17:39:28.063545Z","shell.execute_reply.started":"2025-10-11T17:39:12.469792Z","shell.execute_reply":"2025-10-11T17:39:28.062862Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/tokpidjin\n======================================================================\nKAGGLE GPU SETUP\n======================================================================\n✓ CuPy available\n  CuPy version: 13.6.0\n  GPU: NVIDIA L4\n✓ NumPy available (version 1.26.4)\n\n======================================================================\nRUNNING TESTS\n======================================================================\n\nCuPy GPU support enabled for Kaggle\nGenerated 16 test grids\n\n======================================================================\nGPU O_G UNIT TESTS\n======================================================================\nGPU Available: True\nTest Grids: 16\nModes to Test: 0-7 (8 modes)\nTotal Tests: 128\n\n======================================================================\nCORRECTNESS TESTS\n======================================================================\n\n----------------------------------------------------------------------\nCorrectness Tests: 128 passed, 0 failed\nTotal: 128 tests\n✓ ALL TESTS PASSED!\n\n======================================================================\nPERFORMANCE TESTS\n======================================================================\n\nTested on 13 grids (size >= 9)\n\nMode   CPU (ms)     GPU-FS (ms)  GPU-T (ms)   Speedup-FS   Speedup-T   \n----------------------------------------------------------------------\n0      0.648        0.798        0.749        0.81        x 0.86        x\n1      0.398        1.505        1.458        0.26        x 0.27        x\n2      1.502        0.796        0.727        1.89        x 2.07        x\n3      0.743        1.468        1.424        0.51        x 0.52        x\n4      0.667        2.733        2.664        0.24        x 0.25        x\n5      0.391        2.820        2.770        0.14        x 0.14        x\n6      1.520        2.659        2.586        0.57        x 0.59        x\n7      0.743        2.769        2.710        0.27        x 0.27        x\n----------------------------------------------------------------------\nAVG    0.826        1.943        1.886        0.43        x 0.44        x\n\nExpected Performance:\n  CPU: 4-7ms\n  GPU (frozenset): 1.45-2.15ms (2.3-4.8x speedup)\n  GPU (tuple): 0.95-1.65ms (2.5-7.8x speedup)\n\n✗ Frozenset speedup below expectations (0.43x < 2.3x)\n✗ Tuple speedup below expectations (0.44x < 2.5x)\n\n======================================================================\nTEST SUMMARY\n======================================================================\n✓ ALL CORRECTNESS TESTS PASSED\n\nReady for Kaggle testing!\n======================================================================\n\n======================================================================\nPROFILED SOLVER INTEGRATION TEST\n======================================================================\n\nTest grid: 10x10\nTesting mode 3 (non-bg, 8-connectivity) - common in profiled solvers\n\nResults (100 runs, median):\n  CPU:              2.771 ms\n  GPU (frozenset):  1.486 ms (1.86x speedup)\n  GPU (tuple):      1.476 ms (1.88x speedup)\n\nExpected performance:\n  CPU: 4-7ms\n  GPU (frozenset): 1.45-2.15ms (2.3-4.8x speedup)\n  GPU (tuple): 0.95-1.65ms (2.5-7.8x speedup)\n\n⚠ Frozenset speedup below expectations (1.86x < 2.3x)\n⚠ Tuple speedup below expectations (1.88x < 2.5x)\n\n✓ Results match (correctness verified)\n\n======================================================================\nFINAL SUMMARY\n======================================================================\n✓ ALL CORRECTNESS TESTS PASSED\n✓ Ready for Week 2: Solver Integration\n======================================================================\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"'''\n# let's try to make a submission\n\nsubmission = dict()\n# iterate over all tasks\nfor key, task in tqdm.tqdm(test_challenges.items()):\n    train_inputs = [example['input'] for example in task['train']]\n    train_outputs = [example['output'] for example in task['train']]\n    hypotheses = []\n    # iterate over all programs\n    for program_string, program in programs.items():\n        try:\n            if all([program(i) == o for i, o in zip(train_inputs, train_outputs)]):\n                # remember program if it explains all training examples\n                hypotheses.append(program_string)\n        except:\n            pass\n    # select first program for making predictions\n    predictions = [example['input'] for example in task['test']]\n    if len(hypotheses) > 0:\n        print(f'found {len(hypotheses)} candidate programs for task {key}!')\n        program_string = hypotheses[0]\n        program = eval(program_string)\n        try:\n            predictions = [program(example['input']) for example in task['test']]\n        except:\n            pass\n    submission[key] = [{'attempt_1': grid, 'attempt_2': grid} for grid in predictions]\nprint(f'\\nMade guesses for {len(guesses)} tasks')\n\nwith open('submission.json', 'w') as fp:\n    json.dump(submission, fp)\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}