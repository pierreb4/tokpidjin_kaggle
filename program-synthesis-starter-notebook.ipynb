{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaL4","dataSources":[{"sourceId":67357,"databundleVersionId":8951125,"sourceType":"competition"},{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"},{"sourceId":13310321,"sourceType":"datasetVersion","datasetId":7010692}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Looking at the the tasks from the [Abstraction and Reasoning Corpus](https://github.com/fchollet/ARC), while each task is unique, it is clear that there are certain concepts, such as operations like rotation or mirroring, that occur repeatedly throughout the corpus. What seems feasible is to think of a set of building blocks that encapsulate those concepts that can then be used to build solution programs, that is, task-specific programs that correctly transform each of the input grids of a given task into its corresponding output grid. Such a set of building blocks is a form of domain-specific language (DSL). A DSL defines a set of programs that it can express, and the process of finding or creating such a program solving a given task is a form of program synthesis. Building a good DSL that well captures the explicitly stated core knowledge priors of ARC in an abstract and combinable manner, combined with an adequate program synthesis approach is suggested as a possible way to tackling ARC by its creator FranÃ§ois in [On the Measure of Intelligence](https://arxiv.org/abs/1911.01547).","metadata":{}},{"cell_type":"markdown","source":"This notebook presents a very simple such DSL tailored to ARC and how it can be used to perform program synthesis, intended to serve as a starting point for anyone new to the ARC benchmark. For the sake of demonstration, the DSL as well as the program synthesis are overly simplistic here, to the point of being naive, as will be demonstrated. First, the DSL is defined as some basic functions, also called primitives, that transform grids. Second, program synthesis as search over compositions of those primitives is performed. The search is naive in that it is a brute force search over all possible primitive compositions up to a certain depth that is done for each task and simply uses the first program it finds to solve the training examples to make predictions for the test examples.","metadata":{}},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport tqdm\nimport itertools\n\nfrom random import sample\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap, Normalize","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2024 inputs at /kaggle/input/arc-prize-2024\n# 2025 inputs at /kaggle/input/arc-prize-2025\n\n# train_challenges_path = '../input/arc-prize-2024/arc-agi_training_challenges.json'\n# train_solutions_path = '../input/arc-prize-2024/arc-agi_training_solutions.json'\n# test_challenges_path = '../input/arc-prize-2024/arc-agi_test_challenges.json'\n\ntrain_challenges_path = '../input/arc-prize-2025/arc-agi_training_challenges.json'\ntrain_solutions_path = '../input/arc-prize-2025/arc-agi_training_solutions.json'\ntest_challenges_path = '../input/arc-prize-2025/arc-agi_test_challenges.json'\n\nwith open(train_challenges_path) as fp:\n    train_challenges = json.load(fp)\nwith open(train_solutions_path) as fp:\n    train_solutions = json.load(fp)\nwith open(test_challenges_path) as fp:\n    test_challenges = json.load(fp)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!echo $HOME\n!pwd\n!uname -a\n!cat /etc/debian_version\n!python --version\n\n!python -m cupyx.tools.install_library --library cudnn --cuda 12.x\n!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1\n!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1/lib/libcudnn_cnn_infer.so.8.8.1\n!cp -R /root/.cupy /kaggle/working","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvidia-smi\n!nvcc --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T10:48:48.643872Z","iopub.execute_input":"2025-10-09T10:48:48.644135Z","iopub.status.idle":"2025-10-09T10:48:48.960375Z","shell.execute_reply.started":"2025-10-09T10:48:48.644114Z","shell.execute_reply":"2025-10-09T10:48:48.959419Z"}},"outputs":[{"name":"stdout","text":"Thu Oct  9 10:48:48 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   33C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2024 NVIDIA Corporation\nBuilt on Thu_Jun__6_02:18:23_PDT_2024\nCuda compilation tools, release 12.5, V12.5.82\nBuild cuda_12.5.r12.5/compiler.34385749_0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!ls -ld /usr/local/cuda*\n!ls -ld /usr/local/cuda-12.5/targets/x86_64-linux/lib/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T11:09:58.141481Z","iopub.execute_input":"2025-10-09T11:09:58.141744Z","iopub.status.idle":"2025-10-09T11:09:58.490032Z","shell.execute_reply.started":"2025-10-09T11:09:58.141720Z","shell.execute_reply":"2025-10-09T11:09:58.489269Z"}},"outputs":[{"name":"stdout","text":"lrwxrwxrwx 1 root root   22 Jul 10  2024 /usr/local/cuda -> /etc/alternatives/cuda\nlrwxrwxrwx 1 root root   25 Jul 10  2024 /usr/local/cuda-12 -> /etc/alternatives/cuda-12\ndrwxr-xr-x 1 root root 4096 Jul 10  2024 /usr/local/cuda-12.5\ndrwxr-xr-x 1 root root 4096 Jul 10  2024 /usr/local/cuda-12.5/targets/x86_64-linux/lib/\ncat: /usr/local/cuda-12.5/include/cudnn_version.h: No such file or directory\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# !python -m cupyx.tools.install_library --library cudnn --cuda 12.x\n\n# !ls -ld /kaggle/working/.cupy\n# !cp -R /kaggle/working/.cupy /root\n\n# !ls -l /root/.cupy/cuda_lib/12.x/cudnn/8.8.1/include\n!sudo cp -P /kaggle/working/.cupy/cuda_lib/12.x/cudnn/8.8.1/include/* /usr/local/cuda-12.5/include/\n\n# !ls -l /root/.cupy/cuda_lib/12.x/cudnn/8.8.1/lib\n!sudo cp -P /kaggle/working/.cupy/cuda_lib/12.x/cudnn/8.8.1/lib/* /usr/local/cuda-12.5/lib64/\n\n# !ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1/lib/libcudnn_cnn_infer.so.8.8.1\n# !(export LD_LIBRARY_PATH=/root/.cupy/cuda_lib/12.x/cudnn/8.8.1/lib:$LD_LIBRARY_PATH; echo $LD_LIBRARY_PATH; sudo ldconfig)\n\n!cp -R /kaggle/input/arc-prize-2025 /kaggle/working\n!cp -R /kaggle/input/tokpidjin      /kaggle/working\n!(cd tokpidjin; bash ./run_card.sh -b -c -1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -ltr tokpidjin/*_run.py\n!ls -ltr tokpidjin/*_run.log","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T12:16:44.927979Z","iopub.execute_input":"2025-10-09T12:16:44.928557Z","iopub.status.idle":"2025-10-09T12:16:45.270162Z","shell.execute_reply.started":"2025-10-09T12:16:44.928522Z","shell.execute_reply":"2025-10-09T12:16:45.269335Z"}},"outputs":[{"name":"stdout","text":"-rw-r--r-- 1 root root 207217 Oct  9 11:42 tokpidjin/tmp_batt_ssEzerSYJN_run.py\n-rw-r--r-- 1 root root 202195 Oct  9 11:42 tokpidjin/tmp_batt_Vhrqz1wWjf_run.py\n-rw-r--r-- 1 root root 237094 Oct  9 11:42 tokpidjin/tmp_batt_Tf1Sk6iz8o_run.py\n-rw-r--r-- 1 root root 212958 Oct  9 11:42 tokpidjin/tmp_batt_yRK9YP8kbU_run.py\n-rw-r--r-- 1 root root 194420 Oct  9 11:42 tokpidjin/tmp_batt_iqfsqyi85P_run.py\n-rw-r--r-- 1 root root 184976 Oct  9 11:42 tokpidjin/tmp_batt_8bTdm7K3Ty_run.py\n-rw-r--r-- 1 root root 187512 Oct  9 11:42 tokpidjin/tmp_batt_AunbJSfGTi_run.py\n-rw-r--r-- 1 root root 194097 Oct  9 11:42 tokpidjin/tmp_batt_UJnsDbyauB_run.py\n-rw-r--r-- 1 root root 244440 Oct  9 11:42 tokpidjin/tmp_batt_9kyN8T2Krd_run.py\n-rw-r--r-- 1 root root 191813 Oct  9 11:42 tokpidjin/tmp_batt_Ubwg2mvr5p_run.py\n-rw-r--r-- 1 root root 186404 Oct  9 11:42 tokpidjin/tmp_batt_amDOtUT614_run.py\n-rw-r--r-- 1 root root 234004 Oct  9 11:42 tokpidjin/tmp_batt_wQRodgqB0c_run.py\n-rw-r--r-- 1 root root 215268 Oct  9 11:42 tokpidjin/tmp_batt_64EprUPZDP_run.py\n-rw-r--r-- 1 root root 233240 Oct  9 11:42 tokpidjin/tmp_batt_HJ5CNrlXxt_run.py\n-rw-r--r-- 1 root root 237496 Oct  9 11:42 tokpidjin/tmp_batt_4fPClcwsG4_run.py\n-rw-r--r-- 1 root root 192611 Oct  9 11:42 tokpidjin/tmp_batt_yKZIUibzo2_run.py\n-rw-r--r-- 1 root root 233343 Oct  9 11:42 tokpidjin/tmp_batt_sTpLu6yXuH_run.py\n-rw-r--r-- 1 root root 224204 Oct  9 11:42 tokpidjin/tmp_batt_1W8hBUWcQ4_run.py\n-rw-r--r-- 1 root root 202418 Oct  9 11:42 tokpidjin/tmp_batt_u7uVEr7j8y_run.py\n-rw-r--r-- 1 root root 202498 Oct  9 11:42 tokpidjin/tmp_batt_onerun_run.py\n-rw-r--r-- 1 root root 251868 Oct  9 11:42 tokpidjin/tmp_batt_jWcXKqp1Wx_run.py\n-rw-r--r-- 1 root root 235518 Oct  9 11:42 tokpidjin/tmp_batt_Miibkhi9D6_run.py\n-rw-r--r-- 1 root root 201850 Oct  9 11:42 tokpidjin/tmp_batt_EHgnrPYmg6_run.py\n-rw-r--r-- 1 root root 199754 Oct  9 11:42 tokpidjin/tmp_batt_ZYYqP8spg5_run.py\n-rw-r--r-- 1 root root 203172 Oct  9 11:42 tokpidjin/tmp_batt_T03eywVYtG_run.py\n-rw-r--r-- 1 root root 242796 Oct  9 11:42 tokpidjin/tmp_batt_fDrNTFDS1x_run.py\n-rw-r--r-- 1 root root 222782 Oct  9 11:43 tokpidjin/tmp_batt_VDWyo4nHGv_run.py\n-rw-r--r-- 1 root root 240004 Oct  9 11:48 tokpidjin/tmp_batt_O68AE3mC68_run.py\n-rw-r--r-- 1 root root 217669 Oct  9 12:02 tokpidjin/tmp_batt_zJrcIgSbmv_run.py\n-rw-r--r-- 1 root root 209753 Oct  9 12:09 tokpidjin/tmp_batt_Ieah3leJUe_run.py\n-rw-r--r-- 1 root root 226475 Oct  9 12:14 tokpidjin/tmp_batt_omJbLiyFXy_run.py\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_iqfsqyi85P_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_wQRodgqB0c_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_T03eywVYtG_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_yKZIUibzo2_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_EHgnrPYmg6_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_UJnsDbyauB_run.log\n-rw-r--r-- 1 root root 1453 Oct  9 11:42 tokpidjin/tmp_batt_jWcXKqp1Wx_run.log\n-rw-r--r-- 1 root root 1404 Oct  9 11:42 tokpidjin/tmp_batt_1W8hBUWcQ4_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_Vhrqz1wWjf_run.log\n-rw-r--r-- 1 root root 1404 Oct  9 11:42 tokpidjin/tmp_batt_yRK9YP8kbU_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_AunbJSfGTi_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_amDOtUT614_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_8bTdm7K3Ty_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_Miibkhi9D6_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_9kyN8T2Krd_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_ssEzerSYJN_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_Tf1Sk6iz8o_run.log\n-rw-r--r-- 1 root root 1404 Oct  9 11:42 tokpidjin/tmp_batt_HJ5CNrlXxt_run.log\n-rw-r--r-- 1 root root 1404 Oct  9 11:42 tokpidjin/tmp_batt_64EprUPZDP_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_ZYYqP8spg5_run.log\n-rw-r--r-- 1 root root  596 Oct  9 11:42 tokpidjin/tmp_batt_Ubwg2mvr5p_run.log\n-rw-r--r-- 1 root root  113 Oct  9 11:42 tokpidjin/tmp_batt_LzmtvbhAfW_run.log\n-rw-r--r-- 1 root root 1404 Oct  9 11:42 tokpidjin/tmp_batt_onerun_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_4fPClcwsG4_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_fDrNTFDS1x_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:42 tokpidjin/tmp_batt_u7uVEr7j8y_run.log\n-rw-r--r-- 1 root root 1404 Oct  9 11:42 tokpidjin/tmp_batt_sTpLu6yXuH_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:43 tokpidjin/tmp_batt_VDWyo4nHGv_run.log\n-rw-r--r-- 1 root root    0 Oct  9 11:48 tokpidjin/tmp_batt_O68AE3mC68_run.log\n-rw-r--r-- 1 root root    0 Oct  9 12:02 tokpidjin/tmp_batt_zJrcIgSbmv_run.log\n-rw-r--r-- 1 root root    0 Oct  9 12:09 tokpidjin/tmp_batt_Ieah3leJUe_run.log\n-rw-r--r-- 1 root root    0 Oct  9 12:14 tokpidjin/tmp_batt_omJbLiyFXy_run.log\nls: cannot access 'tokpidjin/pile.log': No such file or directory\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def plot_task(task):\n    \"\"\" plots a task \"\"\"\n    examples = task['train']\n    n_examples = len(examples)\n    cmap = ListedColormap([\n        '#000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n        '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'\n    ])\n    norm = Normalize(vmin=0, vmax=9)\n    figure, axes = plt.subplots(2, n_examples, figsize=(n_examples * 4, 8))\n    for column, example in enumerate(examples):\n        axes[0, column].imshow(example['input'], cmap=cmap, norm=norm)\n        axes[1, column].imshow(example['output'], cmap=cmap, norm=norm)\n        axes[0, column].axis('off')\n        axes[1, column].axis('off')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# defining a handful of basic primitives\n\ndef tophalf(grid):\n    \"\"\" upper half \"\"\"\n    return grid[:len(grid) // 2]\n\n\ndef rot90(grid):\n    \"\"\" clockwise rotation by 90 degrees \"\"\"\n    return list(zip(*grid[::-1]))\n\n\ndef hmirror(grid):\n    \"\"\" mirroring along horizontal \"\"\"\n    return grid[::-1]\n\n\ndef compress(grid):\n    \"\"\" removes frontiers \"\"\"\n    ri = [i for i, r in enumerate(grid) if len(set(r)) == 1]\n    ci = [j for j, c in enumerate(zip(*grid)) if len(set(c)) == 1]\n    return [[v for j, v in enumerate(r) if j not in ci] for i, r in enumerate(grid) if i not in ri]\n\n\ndef trim(grid):\n    \"\"\" removes border \"\"\"\n    return [r[1:-1] for r in grid[1:-1]]\n\n\n# defining the DSL as the set of the primitives\n\nDSL_primitives = {tophalf, rot90, hmirror, compress, trim}\nprimitive_names = {p.__name__ for p in DSL_primitives}\nprint(f'DSL consists of {len(DSL_primitives)} primitives: {primitive_names}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# the maximum composition depth to consider\nMAX_DEPTH = 4\n\n# construct the program strings of all programs expressible by composing at most MAX_DEPTH primitives\n\nprogram_strings = []\nfor depth in range(1, MAX_DEPTH+1):\n    primitive_tuples = itertools.product(*[primitive_names]*depth)\n    for primitives in primitive_tuples:\n        left_side = \"\".join([p + \"(\" for p in primitives])\n        right_side = ')' * depth\n        program_string = f'lambda grid: {left_side}grid{right_side}'\n        program_strings.append(program_string)\n\n\n# print some of the program strings\nprint(f'Space to search consists of {len(program_strings)} programs:\\n')\nprint('\\n'.join([*program_strings[:10], '...']))\n\n\n# map program strings to programs\nprograms = {prog_str: eval(prog_str) for prog_str in program_strings}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for each task, search over the programs and if a working program is found, remember it\n\nguesses = dict()\n# iterate over all tasks\nfor key, task in tqdm.tqdm(train_challenges.items()):\n    train_inputs = [example['input'] for example in task['train']]\n    train_outputs = [example['output'] for example in task['train']]\n    hypotheses = []\n    # iterate over all programs\n    for program_string, program in programs.items():\n        try:\n            if all([program(i) == o for i, o in zip(train_inputs, train_outputs)]):\n                # remember program if it explains all training examples\n                hypotheses.append(program_string)\n        except:\n            pass\n    # select first program for making predictions\n    if len(hypotheses) > 0:\n        print(f'found {len(hypotheses)} candidate programs for task {key}!')\n        guesses[key] = hypotheses[0]\nprint(f'\\nMade guesses for {len(guesses)} tasks')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# make predictions and evaluate them\n\nsolved = dict()\n\n# iterate over all tasks for which a guess exists\nfor key, program_string in guesses.items():\n    test_inputs = [example['input'] for example in train_challenges[key]['test']]\n    program = eval(program_string)\n    if all([program(i) == o for i, o in zip(test_inputs, train_solutions[key])]):\n        # mark predition as correct if all test examples are solved by the program\n        solved[key] = program_string\n\n\nprint(f'Predictions correct for {len(solved)}/{len(guesses)} tasks')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# visualize solved tasks\nfor key, program_string in solved.items():\n    print(f'For task \"{key}\", found program \"{program_string}\"')\n    plot_task(train_challenges[key])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"While this code runs extremely fast (considering 400 tasks in less than 10 seconds), it also performs extremely poor (solving only 4/400 tasks, giving a mere 1% accuracy). How could it be improved? What can be learned from it? There are at least two issues with the above approach to searching a space of programs expressible in a DSL: First, the DSL provided here is not very expressive in that for most tasks, no program that solves it exists in the set of all possible programs buildable in the DSL. Second, even if sufficient expressivity is guaranteed (e.g. via a turing-complete DSL), for which by definition there would exist solution programs to each task, such programs may in practice either not be discoverable in the first place or not detectable as correct programs.","metadata":{}},{"cell_type":"markdown","source":"### Increasing DSL Expressivity\nIt is obvious why some tasks can't be solved by the above DSL, but one simple proof would be the following: No primitive ever increases the pixel count of a grid, hence neither can any composition of the primitives ever do so - and since for certain tasks, the output grids do have more pixels than the input grids, the DSL is incomplete. To increase the expressivity of the program space (disregarding the maximum program size), one will want to expand the set of the primitives and also extend the structure of the considered programs beyond mere composition. Maybe it is a good idea to have primitives which take more than one input argument, or primitives that operate on types other than only grids, such as objects or integers. Note that viewing the transformations from inputs to outputs as a linear function composition is very misleading, as many tasks can't be neatly squeezed into this form: Some tasks seem much better addressed on a pixel- or object-level than on a grid-level. A good DSL is probably concise and allows expressing solutions to many tasks as short programs. Such a DSL may best be built by bootstrapping, that is, building a minimal version of it and then iterating back and forth between using it to solve ARC tasks and expanding it to account for unsolvable ARC tasks, all while having abstractness and flexibility of the primitives and how they can interplay in mind.","metadata":{}},{"cell_type":"code","source":"# example of task where above DSL is ill-suited and e.g. an object-centric view could be more appropriate.\n# Potentially useful primitives: object extraction, property detection (has 6 pixels) and transformations (recolor)\nplot_task(train_challenges['d2abd087'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# example of task where above DSL is ill-suited and e.g. a more pixel-centric view could be more appropriate.\n# Potentially useful: cellular automata\nplot_task(train_challenges['3906de3d'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Increasing Search Efficiency\nTo increase the efficiency of the search for programs, it is crucial to avoid a brute force search, as it very quickly becomes entirely infeasible as the size of the programs and the number of primitives grow: Even for a simplistic DSL where the primitives can only interact with each other via composition, if it consists of p primitives and one wants to check all programs up to depth d, the number of programs to consider with grow on the order of $p^d$.","metadata":{}},{"cell_type":"markdown","source":"Naively, \"pruning the search space\" or avoiding considering primitives or subprograms unlikely useful for a solution program could be addressed by building heuristics into the search, e.g. \"whenever the output grid is always of the same size as the input grid for all training examples, don't consider grid rescaling operations during the search\". However, not only would such an approach be extremely labour-intensive, but also likely prone to result in a brittle and static system that would performs poorly. Maybe the navigation of the search space is something that can or even should be learned, not hardcoded.","metadata":{}},{"cell_type":"code","source":"# some calculations on infeasibility of brute force search\npd_arr = [(p, d) for p in [8, 16, 32] for d in [2, 4, 8]]\nfor p, d in sorted(pd_arr, key=lambda pd: pd[0]**pd[1]):\n    print(f'DSL with {p} primitives and max. depth {d} allows > {p**d} programs')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Outlook\n\nCreating your own DSL from scratch will probably not be easy and may not be desired or needed in the first place. There are at least two open-source DSLs for ARC, for example [Johan's DSL](https://github.com/top-quarks/ARC-solution) which he also used to win the first ARC-competition in 2020 with 20.6% by having efficient implementations and simple primitive signatures rendering a large-scale search feasible. Alternatively, I have built a separate, less minimal [ARC-DSL](https://github.com/michaelhodel/arc-dsl) that comes alongside reference [solution programs for all 400 ARC training tasks](https://github.com/michaelhodel/arc-dsl/blob/main/solvers.py) and which was also used for more recent program synthesis approaches such as [CodeIt](https://arxiv.org/pdf/2402.04858) that may be useful, even if just as inspiration. However, not following other's footsteps can also have benefits, such as not having to work with something that may be suboptimal for the desired approach at hand and by that getting stuck in a local minimum, and maybe a more adequate DSL for ARC is yet to be created, maybe by you!\n\nAnd, of course, using a DSL and searching over it is by no means the only way or all there is to ARC. Arguably, much work is yet to be done, and novelty and diversity in approaches seem in dire need to make progress on the benchmark, and with that hopefully ultimaltely towards much more advanced AI.\n\nHappy ARC-ing and good luck with the ARC-prize!","metadata":{}},{"cell_type":"code","source":"# let's try to make a submission\n\nsubmission = dict()\n# iterate over all tasks\nfor key, task in tqdm.tqdm(test_challenges.items()):\n    train_inputs = [example['input'] for example in task['train']]\n    train_outputs = [example['output'] for example in task['train']]\n    hypotheses = []\n    # iterate over all programs\n    for program_string, program in programs.items():\n        try:\n            if all([program(i) == o for i, o in zip(train_inputs, train_outputs)]):\n                # remember program if it explains all training examples\n                hypotheses.append(program_string)\n        except:\n            pass\n    # select first program for making predictions\n    predictions = [example['input'] for example in task['test']]\n    if len(hypotheses) > 0:\n        print(f'found {len(hypotheses)} candidate programs for task {key}!')\n        program_string = hypotheses[0]\n        program = eval(program_string)\n        try:\n            predictions = [program(example['input']) for example in task['test']]\n        except:\n            pass\n    submission[key] = [{'attempt_1': grid, 'attempt_2': grid} for grid in predictions]\nprint(f'\\nMade guesses for {len(guesses)} tasks')\n\nwith open('submission.json', 'w') as fp:\n    json.dump(submission, fp)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}