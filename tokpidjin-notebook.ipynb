{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67357,"databundleVersionId":8951125,"sourceType":"competition"},{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"},{"sourceId":13391999,"sourceType":"datasetVersion","datasetId":7010692}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n!echo $HOME\n!pwd\n!uname -a\n!cat /etc/debian_version\n!python --version\n\n!python -m cupyx.tools.install_library --library cudnn --cuda 12.x\n!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1\n!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1/lib/libcudnn_cnn_infer.so.8.8.1\n!cp -R /root/.cupy /kaggle/working\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n# let's try to make a submission\n\nsubmission = dict()\n# iterate over all tasks\nfor key, task in tqdm.tqdm(test_challenges.items()):\n    train_inputs = [example['input'] for example in task['train']]\n    train_outputs = [example['output'] for example in task['train']]\n    hypotheses = []\n    # iterate over all programs\n    for program_string, program in programs.items():\n        try:\n            if all([program(i) == o for i, o in zip(train_inputs, train_outputs)]):\n                # remember program if it explains all training examples\n                hypotheses.append(program_string)\n        except:\n            pass\n    # select first program for making predictions\n    predictions = [example['input'] for example in task['test']]\n    if len(hypotheses) > 0:\n        print(f'found {len(hypotheses)} candidate programs for task {key}!')\n        program_string = hypotheses[0]\n        program = eval(program_string)\n        try:\n            predictions = [program(example['input']) for example in task['test']]\n        except:\n            pass\n    submission[key] = [{'attempt_1': grid, 'attempt_2': grid} for grid in predictions]\nprint(f'\\nMade guesses for {len(guesses)} tasks')\n\nwith open('submission.json', 'w') as fp:\n    json.dump(submission, fp)\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !nvidia-smi\n# !nvcc --version","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run after getting new machine\n!pip install loky","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T19:47:15.371786Z","iopub.execute_input":"2025-10-15T19:47:15.372060Z","iopub.status.idle":"2025-10-15T19:47:19.794552Z","shell.execute_reply.started":"2025-10-15T19:47:15.372041Z","shell.execute_reply":"2025-10-15T19:47:19.793628Z"}},"outputs":[{"name":"stdout","text":"Collecting loky\n  Downloading loky-3.5.6-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from loky) (3.1.1)\nDownloading loky-3.5.6-py3-none-any.whl (56 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: loky\nSuccessfully installed loky-3.5.6\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# To reinstall cudnn, enable internet and uncomment the next 3 lines\n# !rm -rf /root/.cupy\n# !python -m cupyx.tools.install_library --library cudnn --cuda 12.x\n# !cp -R /root/.cupy /kaggle/working\n\n!rm -rf /root/.cupy\n!cp -R /kaggle/working/.cupy /root\n!cp -R /kaggle/input/arc-prize-2025 /kaggle/working\n!cp -R /kaggle/input/tokpidjin      /kaggle/working\n\n%cd /kaggle/working/tokpidjin\n\n# Only run run_card.sh here if it has -i\n!bash run_card.sh -o -i -b -c -1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T08:01:59.180898Z","iopub.execute_input":"2025-10-16T08:01:59.181112Z","iopub.status.idle":"2025-10-16T08:02:27.007204Z","shell.execute_reply.started":"2025-10-16T08:01:59.181095Z","shell.execute_reply":"2025-10-16T08:02:27.006257Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/tokpidjin\nInitial run - removing old solvers\nCuPy GPU support enabled for Kaggle\n=== GPU DETECTED - USING CPU MODE (vectorized is broken) ===\n0, Tesla T4, 15360 MiB\n1, Tesla T4, 15360 MiB\nCard.py: Generating standard batt for CPU\nTimeout: 10.0s\nThu Oct 16 08:02:22 AM UTC 2025\n-- One run only --\nGenerating batt: python card.py  -c 32  -f tmp_batt_onerun_run.py\nCuPy GPU support enabled for Kaggle\ncard.py:619: len(all_solvers) = 323\ncard.py:557: old_name = 'x6' - old_call = 'get_nth_t(t4, F0)'\ncard.py:558: code.t_call[code.t_num] = 'get_nth_t, t4, F1'\ncard.py:350: old_hint = 'Tuple[Tuple[Tuple[int, int, int], ...], ...]'\ncard.py:350: old_hint = 'Tuple[Tuple[Tuple[int, int, int], ...], ...]'\ncard.py:350: old_hint = 'Tuple[Tuple[Tuple[int, int, int], ...], ...]'\ncard.py:350: old_hint = 'Tuple[Tuple[Tuple[int, int, int], ...], ...]'\ncard.py:350: old_hint = 'Tuple[Tuple[Tuple[int, int, int], ...], ...]'\ncard.py:286: item = 't75'\ncard.py:350: old_hint = 'Tuple[Tuple[Tuple[int, int, int], ...], ...]'\ncard.py:350: old_hint = 'Tuple[Tuple[Tuple[int, int, int], ...], ...]'\ncard.py:350: old_hint = 'Tuple[Tuple[Tuple[int, int, int], ...], ...]'\ncard.py:286: item = 't85'\ncard.py:286: item = 'TWO_BY_ZERO'\ncard.py:286: item = 't227'\ncard.py:286: item = 'FOUR'\ncard.py:286: item = 'FOUR'\ncard.py:350: old_hint = 'Tuple[Tuple[Tuple[int, int, int], ...], ...]'\nRunning: timeout -k 5s 2s python run_batt.py -t 10.0 -c -1 -b tmp_batt_onerun_run \nCuPy GPU support enabled for Kaggle\nKaggle GPU Support: True (2 devices)\n  GPU 0: Compute 75, Memory: 14.7GB\n  GPU 1: Compute 75, Memory: 14.7GB\n✓ Kaggle GPU Optimizer initialized\nMultiGPUOptimizer initialized with 2/2 GPUs\nMultiGPUOptimizer initialized with 2/2 GPUs\nBatt GPU: Enabled (2 GPUs, MultiGPUOptimizer)\nrun_batt.py:1378: -- b27ca6d3 - 0 start --\nrun_batt.py:638: demo[0] - b27ca6d3 - 32\nrun_batt.py:647: - o_solver_id = 'b27ca6d3' - match = True\nrun_batt.py:638: demo[1] - b27ca6d3 - 32\nrun_batt.py:647: - o_solver_id = 'b27ca6d3' - match = True\nrun_batt.py:638: test[0] - b27ca6d3 - 32\nrun_batt.py:647: - o_solver_id = 'b27ca6d3' - match = True\nrun_batt.py:1388: -- b27ca6d3 - 0 done - 80 candidates scored\nrun_batt.py:1444: -- Filtered to 32 unique candidates (from 80)\n1 tasks - 1 timeouts\n\n=== Cache Statistics ===\n\nValidation Cache:\n  Hits: 0\n  Misses: 32\n  Total: 32\n  Hit Rate: 0.0%\n  Cache Size: 32 entries\n\nInlining Cache:\n  Hits: 128\n  Misses: 32\n  Total: 160\n  Hit Rate: 80.0%\n  Cache Size: 36 entries\n  Time Saved: ~19.20s\n\nTotal Time Saved: ~19.20s\nThu Oct 16 08:02:26 AM UTC 2025\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd /kaggle/working/tokpidjin\n\n!python profile_batt_framework.py --tasks 100 --top 30","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T08:02:32.699529Z","iopub.execute_input":"2025-10-16T08:02:32.699743Z","iopub.status.idle":"2025-10-16T08:02:38.235300Z","shell.execute_reply.started":"2025-10-16T08:02:32.699724Z","shell.execute_reply":"2025-10-16T08:02:38.234552Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/tokpidjin\nCuPy GPU support enabled for Kaggle\nMultiGPUOptimizer initialized with 2/2 GPUs\nMultiGPUOptimizer initialized with 2/2 GPUs\nBatt GPU: Enabled (2 GPUs, MultiGPUOptimizer)\n\n================================================================================\nFRAMEWORK PROFILING: 100 tasks\n================================================================================\n\nLoaded 100 tasks for profiling\n\nStarting profiling...\nProfiling complete: 4.00s wall-clock time\n\nResults: 3200 outputs, 13200 solvers\n\n\n================================================================================\nFRAMEWORK BOTTLENECK ANALYSIS\n================================================================================\n\nFramework Bottlenecks by Category (Top 10):\n\nCategory                       Cum Time     % Time     Calls        Functions \n--------------------------------------------------------------------------------\nOther Framework                    11.908s      67.5%     5491459       233\nDSL Operations                      5.074s      28.8%      510444        50\nCandidate Management                0.426s       2.4%      236752         2\nGPU Batch Processing                0.142s       0.8%        1700         1\nTuple Operations                    0.032s       0.2%       32100         5\nDedupe Operations                   0.026s       0.2%        3400         1\nFrozenset Operations                0.021s       0.1%       16000         4\n\n================================================================================\n\nTop Functions by Category:\n\n\nOther Framework (Top 5 functions):\nFunction                                 Calls        Total        Cumulative   Per Call    \n--------------------------------------------------------------------------------\nbatt                                            100       0.069s       3.958s       0.691ms\nf                                             71126       0.024s       2.025s       0.000ms\n<genexpr>                                   1048811       0.142s       0.735s       0.000ms\nshoot                                         23511       0.023s       0.561s       0.001ms\nconnect                                       23739       0.186s       0.539s       0.008ms\n\nDSL Operations (Top 5 functions):\nFunction                                 Calls        Total        Cumulative   Per Call    \n--------------------------------------------------------------------------------\no_g                                            3400       0.027s       1.377s       0.008ms\nobjects                                        3400       0.596s       1.350s       0.175ms\nmapply_t                                       1100       0.100s       0.835s       0.091ms\nfill                                           2100       0.224s       0.247s       0.107ms\napply                                         10114       0.018s       0.219s       0.002ms\n\nCandidate Management (Top 5 functions):\nFunction                                 Calls        Total        Cumulative   Per Call    \n--------------------------------------------------------------------------------\n_get_safe_default                              3033       0.013s       0.404s       0.004ms\n<method 'append' of 'list' objects>          233719       0.022s       0.022s       0.000ms\n\nGPU Batch Processing (Top 5 functions):\nFunction                                 Calls        Total        Cumulative   Per Call    \n--------------------------------------------------------------------------------\nbatch_process_samples_gpu                      1700       0.009s       0.142s       0.005ms\n\nTuple Operations (Top 5 functions):\nFunction                                 Calls        Total        Cumulative   Per Call    \n--------------------------------------------------------------------------------\ndifference_tuple                               8400       0.010s       0.017s       0.001ms\nget_nth_t                                      8800       0.008s       0.010s       0.001ms\nastuple                                       14200       0.002s       0.002s       0.000ms\nmerge_t                                         600       0.001s       0.002s       0.002ms\nremove_t                                        100       0.000s       0.000s       0.002ms\n\n================================================================================\n\nDetailed report saved to: profile_batt_framework_20251016_080237.txt\n\n================================================================================\nPROFILING COMPLETE\n================================================================================\n\nWall-clock time: 4.00s\nReport saved to: profile_batt_framework_20251016_080237.txt\n\nNext steps:\n1. Review top categories to identify main bottlenecks\n2. Focus on categories with >10% of total time\n3. Implement targeted optimizations for top functions\n4. Re-profile to validate improvements\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"%cd /kaggle/working/tokpidjin\n\n# !python diagnose_accuracy.py\n# !python profile_batt_batch.py -f tmp_batt_onerun_run -n 100 -o results.json\n!kernprof -l -v tmp_batt_onerun_run.py","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/tokpidjin\n\n!bash run_card.sh -b -c -32 -g","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/tokpidjin\n\n# !ls solver_dir/solve_*/\n!time python run_test.py -q -i 007bbfb7","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}