{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67357,"databundleVersionId":8951125,"sourceType":"competition"},{"sourceId":91496,"databundleVersionId":11802066,"sourceType":"competition"},{"sourceId":13350375,"sourceType":"datasetVersion","datasetId":7010692}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n!echo $HOME\n!pwd\n!uname -a\n!cat /etc/debian_version\n!python --version\n\n!python -m cupyx.tools.install_library --library cudnn --cuda 12.x\n!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1\n!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1/lib/libcudnn_cnn_infer.so.8.8.1\n!cp -R /root/.cupy /kaggle/working\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n# let's try to make a submission\n\nsubmission = dict()\n# iterate over all tasks\nfor key, task in tqdm.tqdm(test_challenges.items()):\n    train_inputs = [example['input'] for example in task['train']]\n    train_outputs = [example['output'] for example in task['train']]\n    hypotheses = []\n    # iterate over all programs\n    for program_string, program in programs.items():\n        try:\n            if all([program(i) == o for i, o in zip(train_inputs, train_outputs)]):\n                # remember program if it explains all training examples\n                hypotheses.append(program_string)\n        except:\n            pass\n    # select first program for making predictions\n    predictions = [example['input'] for example in task['test']]\n    if len(hypotheses) > 0:\n        print(f'found {len(hypotheses)} candidate programs for task {key}!')\n        program_string = hypotheses[0]\n        program = eval(program_string)\n        try:\n            predictions = [program(example['input']) for example in task['test']]\n        except:\n            pass\n    submission[key] = [{'attempt_1': grid, 'attempt_2': grid} for grid in predictions]\nprint(f'\\nMade guesses for {len(guesses)} tasks')\n\nwith open('submission.json', 'w') as fp:\n    json.dump(submission, fp)\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !nvidia-smi\n# !nvcc --version","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# To reinstall cudnn, enable internet and uncomment the next 3 lines\n# !rm -rf /root/.cupy\n# !python -m cupyx.tools.install_library --library cudnn --cuda 12.x\n# !cp -R /root/.cupy /kaggle/working\n\n!rm -rf /root/.cupy\n!cp -R /kaggle/working/.cupy /root\n!cp -R /kaggle/input/arc-prize-2025 /kaggle/working\n!cp -R /kaggle/input/tokpidjin      /kaggle/working\n\n%cd /kaggle/working/tokpidjin\n\n# !bash run_card.sh -o -i -b -c -32\n# !python run_batt.py --timing -i 007bbfb7 -b tmp_batt_onerun_run 2>&1 | tail -50\n# !python run_batt.py --timing -i 007bbfb7 -b tmp_batt_onerun_run\n# !python -u run_batt.py --timing -i -t 1.0 -c -10 -b tmp_batt_onerun_run\n\n!python prep_solver_dir.py\n# !python card.py -fd -c 32 --vectorized -f batt.py\n\n!echo --\n# !python run_batt.py -c 5 -b batt --timing\n# !bash /kaggle/input/tokpidjin/test_gpu_timeout.sh\n\n# Run 2 - Should see higher cache hits\n!bash run_card.sh -o -c 20 -T\n\n# Run 3 - Should approach 100% cache hits  \n!bash run_card.sh -o -c 20 -T\n\n# Compare\n!grep \"Hit Rate\" tmp_batt_onerun_run.log","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}