{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc154b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:23:42.754134Z",
     "iopub.status.busy": "2025-10-11T19:23:42.753692Z",
     "iopub.status.idle": "2025-10-11T19:23:42.772619Z",
     "shell.execute_reply": "2025-10-11T19:23:42.772129Z"
    },
    "papermill": {
     "duration": 0.022582,
     "end_time": "2025-10-11T19:23:42.773567",
     "exception": false,
     "start_time": "2025-10-11T19:23:42.750985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5265a96c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:23:42.777467Z",
     "iopub.status.busy": "2025-10-11T19:23:42.777014Z",
     "iopub.status.idle": "2025-10-11T19:23:42.788308Z",
     "shell.execute_reply": "2025-10-11T19:23:42.787839Z"
    },
    "papermill": {
     "duration": 0.013949,
     "end_time": "2025-10-11T19:23:42.789172",
     "exception": false,
     "start_time": "2025-10-11T19:23:42.775223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!echo $HOME\\n!pwd\\n!uname -a\\n!cat /etc/debian_version\\n!python --version\\n\\n!python -m cupyx.tools.install_library --library cudnn --cuda 12.x\\n!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1\\n!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1/lib/libcudnn_cnn_infer.so.8.8.1\\n!cp -R /root/.cupy /kaggle/working\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!echo $HOME\n",
    "!pwd\n",
    "!uname -a\n",
    "!cat /etc/debian_version\n",
    "!python --version\n",
    "\n",
    "!python -m cupyx.tools.install_library --library cudnn --cuda 12.x\n",
    "!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1\n",
    "!ls -ld /root/.cupy/cuda_lib/12.x/cudnn/8.8.1/lib/libcudnn_cnn_infer.so.8.8.1\n",
    "!cp -R /root/.cupy /kaggle/working\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537330b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:23:42.792879Z",
     "iopub.status.busy": "2025-10-11T19:23:42.792575Z",
     "iopub.status.idle": "2025-10-11T19:23:42.801429Z",
     "shell.execute_reply": "2025-10-11T19:23:42.800941Z"
    },
    "papermill": {
     "duration": 0.011559,
     "end_time": "2025-10-11T19:23:42.802268",
     "exception": false,
     "start_time": "2025-10-11T19:23:42.790709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi\n",
    "# !nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b497d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:23:42.805883Z",
     "iopub.status.busy": "2025-10-11T19:23:42.805576Z",
     "iopub.status.idle": "2025-10-11T19:23:43.925125Z",
     "shell.execute_reply": "2025-10-11T19:23:43.924451Z"
    },
    "papermill": {
     "duration": 1.122383,
     "end_time": "2025-10-11T19:23:43.926122",
     "exception": false,
     "start_time": "2025-10-11T19:23:42.803739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/kaggle/working/.cupy': No such file or directory\r\n",
      "/kaggle/working/tokpidjin\n"
     ]
    }
   ],
   "source": [
    "# !python -m cupyx.tools.install_library --library cudnn --cuda 12.x\n",
    "# !cp -R /root/.cupy /kaggle/working\n",
    "\n",
    "!cp -R /kaggle/working/.cupy /root\n",
    "!cp -R /kaggle/input/arc-prize-2025 /kaggle/working\n",
    "!cp -R /kaggle/input/tokpidjin      /kaggle/working\n",
    "\n",
    "%cd /kaggle/working/tokpidjin\n",
    "\n",
    "# !bash run_card.sh -o -i -b -c -32\n",
    "# !python verify_gpu_fix.py\n",
    "# !python kaggle_debug_gpu_o_g.py\n",
    "# !python kaggle_deep_debug.py\n",
    "# !python gpu_dsl_core.py\n",
    "# !python verify_fix_works.py\n",
    "# !python benchmark_gpu_solvers.py\n",
    "# !python kaggle_definitive_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffeb808b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:23:43.930588Z",
     "iopub.status.busy": "2025-10-11T19:23:43.930354Z",
     "iopub.status.idle": "2025-10-11T19:23:43.944010Z",
     "shell.execute_reply": "2025-10-11T19:23:43.943513Z"
    },
    "papermill": {
     "duration": 0.016879,
     "end_time": "2025-10-11T19:23:43.944906",
     "exception": false,
     "start_time": "2025-10-11T19:23:43.928027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# let's try to make a submission\\n\\nsubmission = dict()\\n# iterate over all tasks\\nfor key, task in tqdm.tqdm(test_challenges.items()):\\n    train_inputs = [example['input'] for example in task['train']]\\n    train_outputs = [example['output'] for example in task['train']]\\n    hypotheses = []\\n    # iterate over all programs\\n    for program_string, program in programs.items():\\n        try:\\n            if all([program(i) == o for i, o in zip(train_inputs, train_outputs)]):\\n                # remember program if it explains all training examples\\n                hypotheses.append(program_string)\\n        except:\\n            pass\\n    # select first program for making predictions\\n    predictions = [example['input'] for example in task['test']]\\n    if len(hypotheses) > 0:\\n        print(f'found {len(hypotheses)} candidate programs for task {key}!')\\n        program_string = hypotheses[0]\\n        program = eval(program_string)\\n        try:\\n            predictions = [program(example['input']) for example in task['test']]\\n        except:\\n            pass\\n    submission[key] = [{'attempt_1': grid, 'attempt_2': grid} for grid in predictions]\\nprint(f'\\nMade guesses for {len(guesses)} tasks')\\n\\nwith open('submission.json', 'w') as fp:\\n    json.dump(submission, fp)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# let's try to make a submission\n",
    "\n",
    "submission = dict()\n",
    "# iterate over all tasks\n",
    "for key, task in tqdm.tqdm(test_challenges.items()):\n",
    "    train_inputs = [example['input'] for example in task['train']]\n",
    "    train_outputs = [example['output'] for example in task['train']]\n",
    "    hypotheses = []\n",
    "    # iterate over all programs\n",
    "    for program_string, program in programs.items():\n",
    "        try:\n",
    "            if all([program(i) == o for i, o in zip(train_inputs, train_outputs)]):\n",
    "                # remember program if it explains all training examples\n",
    "                hypotheses.append(program_string)\n",
    "        except:\n",
    "            pass\n",
    "    # select first program for making predictions\n",
    "    predictions = [example['input'] for example in task['test']]\n",
    "    if len(hypotheses) > 0:\n",
    "        print(f'found {len(hypotheses)} candidate programs for task {key}!')\n",
    "        program_string = hypotheses[0]\n",
    "        program = eval(program_string)\n",
    "        try:\n",
    "            predictions = [program(example['input']) for example in task['test']]\n",
    "        except:\n",
    "            pass\n",
    "    submission[key] = [{'attempt_1': grid, 'attempt_2': grid} for grid in predictions]\n",
    "print(f'\\nMade guesses for {len(guesses)} tasks')\n",
    "\n",
    "with open('submission.json', 'w') as fp:\n",
    "    json.dump(submission, fp)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaL4",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 11802066,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "datasetId": 7010692,
     "sourceId": 13340419,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.989247,
   "end_time": "2025-10-11T19:23:44.261621",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-11T19:23:39.272374",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
